{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMlvztyK1NbH"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install wandb\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown"
      ],
      "metadata": {
        "id": "caMyL0_62f4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchmetrics\n",
        "from torch.optim import AdamW, lr_scheduler, Adam\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df286d56-dabd-445e-cb31-09367ca17195",
        "id": "IfBO16ZHfouo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AywbDIQSfoun",
        "outputId": "2ac5b133-a3ee-4d9a-f9c0-c1e45a95fc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "\n",
        "wandb.init(\n",
        "    project=\"UFO\",\n",
        "\n",
        "    config={\n",
        "        \"architecture\": \"transformer\",\n",
        "        \"dataset\": \"mydata\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "QZ5dzDaifoup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class textDataset(Dataset):\n",
        "    def __init__(self, texts, targets, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        target = self.targets[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': torch.tensor(encoding['input_ids']).flatten(),\n",
        "            'attention_mask': torch.tensor(encoding['attention_mask']).flatten(),\n",
        "            'targets': torch.tensor(target, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "CNDBbEwi4AT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTextClassifier:\n",
        "    def __init__(self, model_path, tokenizer_path, n_classes=2, models_save_path='/content/best.pt'):\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.models_save_path = models_save_path\n",
        "        self.max_len = 512\n",
        "\n",
        "        self.out_features = self.model.bert.encoder.layer[1].output.dense.out_features\n",
        "        self.model.classifier = torch.nn.Linear(self.out_features, n_classes)\n",
        "\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def init_helpers(self, texts, targets, lr, report_step=250, train_val_test=[0.90, 0.10, 0], batch_size=64, dataset_class=textDataset):\n",
        "        dataset = dataset_class(texts, targets, self.tokenizer)\n",
        "\n",
        "\n",
        "        self.train_data, self.val_data, self.test_data = random_split(dataset, train_val_test)\n",
        "\n",
        "        self.val_loader = DataLoader(self.val_data, batch_size=batch_size, shuffle=True)\n",
        "        self.train_loader = DataLoader(self.train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        self.report_step = report_step\n",
        "\n",
        "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
        "        self.optimizer = Adam(self.model.parameters(), lr)\n",
        "        self.lr_scheduler = lr_scheduler.LinearLR(self.optimizer)\n",
        "\n",
        "    def eval(self):\n",
        "        self.model = self.model.train()\n",
        "        losses = []\n",
        "        correct_predicts = 0\n",
        "        f1_scores = []\n",
        "        f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=3)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                input_ids = batch[\"input_ids\"].to(self.device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
        "                targets = batch[\"targets\"].to(self.device)\n",
        "\n",
        "                outputs = self.model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask\n",
        "                )\n",
        "\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "                loss = self.loss_func(outputs.logits, targets)\n",
        "\n",
        "                f1_scores.append(f1(preds.cpu(), targets.cpu()))\n",
        "\n",
        "                correct_predicts += torch.sum(preds == targets)\n",
        "                losses.append(loss.item())\n",
        "\n",
        "        val_acc = correct_predicts / len(self.val_data)\n",
        "        val_loss = np.mean(losses)\n",
        "        val_f1 = np.mean(f1_scores)\n",
        "        return val_acc, val_loss, val_f1\n",
        "\n",
        "    def train_one_epoch(self):\n",
        "        self.model = self.model.train()\n",
        "        losses = []\n",
        "        correct_predicts = 0\n",
        "\n",
        "\n",
        "        report_counter = 0\n",
        "\n",
        "        for batch in self.train_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(self.device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(self.device)\n",
        "            targets = batch[\"targets\"].to(self.device)\n",
        "\n",
        "            outputs = self.model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            loss = self.loss_func(outputs.logits, targets)\n",
        "\n",
        "\n",
        "            correct_predicts += torch.sum(preds == targets)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "            self.progress_bar.update(1)\n",
        "\n",
        "            if report_counter % self.report_step == 0:\n",
        "                val_acc, val_loss, val_f1 = self.eval()\n",
        "                if self.best_f1 < val_f1:\n",
        "                    torch.save(self.model, self.models_save_path)\n",
        "                    self.best_f1 = val_f1\n",
        "\n",
        "                wandb.log({\"ruBert-base_F1\": val_f1, \"ruBert-base_Acc\": val_acc, 'ruBert-base_loss': val_loss})\n",
        "\n",
        "            report_counter += 1\n",
        "\n",
        "\n",
        "        self.lr_scheduler.step()\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, epochs):\n",
        "        self.progress_bar = tqdm(range(len(self.train_loader)*epochs))\n",
        "        self.best_f1 = 0\n",
        "        for epoch in range(epochs):\n",
        "            self.train_one_epoch()\n",
        "\n",
        "            # val_acc, val_loss = self.eval()\n",
        "\n",
        "            # print(f'Epoch: {epoch + 1}/{epochs} completed')\n",
        "            # print(f'Val loss {val_loss} accuracy {val_acc}')\n",
        "            # if val_acc > best_accuracy:\n",
        "            #     torch.save(self.model, self.model_save_path)\n",
        "            #     best_accuracy = val_acc\n",
        "\n",
        "        # print('Training completed best accuracy is', best_accuracy.item())\n",
        "        # self.model = torch.load(self.model_save_path)\n",
        "\n",
        "    def predict(self, text, ind_to_labels):\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        out = {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten()\n",
        "        }\n",
        "\n",
        "        input_ids = out[\"input_ids\"].to(self.device)\n",
        "        attention_mask = out[\"attention_mask\"].to(self.device)\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids.unsqueeze(0),\n",
        "            attention_mask=attention_mask.unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "        return ind_to_labels[prediction]"
      ],
      "metadata": {
        "id": "1M0JCYJ1THU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('split_data.csv')\n",
        "texts, targets = data['text'], data['class']"
      ],
      "metadata": {
        "id": "yu7Zur7Ztt3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "lr = 3e-4"
      ],
      "metadata": {
        "id": "S1SIJ3uWi4az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = CustomTextClassifier('cointegrated/rubert-tiny', 'cointegrated/rubert-tiny', n_classes=3, models_save_path='/content/drive/MyDrive/models/best.pt')\n",
        "classifier.init_helpers(texts, targets, lr, batch_size=64, train_val_test=[0.98, 0.02, 0], report_step=100)"
      ],
      "metadata": {
        "id": "WzgJgoUUlymN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Linear(312, 312),\n",
        "    torch.nn.Linear(312, 3)\n",
        ")\n",
        "classifier.model.to(classifier.device);"
      ],
      "metadata": {
        "id": "kfD0QkGtKoF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.train(num_epochs)"
      ],
      "metadata": {
        "id": "OIzlgFDZkhHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.model = torch.load('/content/drive/MyDrive/models/best.pt')"
      ],
      "metadata": {
        "id": "vCPyf3YKmecZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "while True:\n",
        "    text = input()\n",
        "    print(classifier.predict(text, {1: 'Обязаности', 0: 'Требования', 2: 'Условия'}))\n",
        "    sleep(3)\n",
        "    clear_output()"
      ],
      "metadata": {
        "id": "IfIBr98B4H8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sjaLKAUc4igk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}